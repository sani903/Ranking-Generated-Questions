{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760cc0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "#importing relevant libraries\n",
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import textstat\n",
    "import language_tool_python\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db31beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select best features using sklearn library\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_classif, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b1f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the ANN on the manually extracted features, using 4 hidden layers with number of neurons \n",
    "# halving with each subsequent layer\n",
    "def train_model_man(X,y):\n",
    "    ann.add(tf.keras.layers.Dense(units=100, activation='relu', input_shape=X[0].shape))\n",
    "    ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "    ann.add(tf.keras.layers.Dense(units=25, activation='relu'))\n",
    "    ann.add(tf.keras.layers.Dense(units=12, activation='relu'))\n",
    "    ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    ann.fit(X, y, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b735bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the ANN on the features extracted using Universal Sentence Encoder, using 2 hidden layers \n",
    "# with number of neurons halving with each subsequent layer\n",
    "def train_model_auto(X,y):\n",
    "    ann2.add(tf.keras.layers.Dense(units=8, activation='relu', input_shape=X[0].shape))\n",
    "    ann2.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "    ann2.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    ann2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    ann2.fit(X, y, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "195d9cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the ANN built on the manually extracted set of features  \n",
    "def test_model_man(fname, X):\n",
    "    dfn = pd.read_csv(fname)\n",
    "    y_pred = ann.predict(X) #y_pred predicts class of each question with a certain confidence\n",
    "    y_bi = y_pred.copy()\n",
    "    y_bi = (y_bi>0.5) #this helps classify each question as either \"good\" or \"bad\"\n",
    "    y_res = np.array(y_pred)\n",
    "    ranking = {}\n",
    "    # for loop is for finding the maximum confidence value in the prediction for class label in y_res\n",
    "    # and ordering the indices of questions in descending order of confidence\n",
    "    for j in range(len(y_res)): \n",
    "        maxi = 0\n",
    "        for i in range(len(y_res)):\n",
    "            if y_res[i]>y_res[maxi]: \n",
    "                maxi=i\n",
    "        y_res[maxi] = 0       \n",
    "        ranking[j] = maxi\n",
    "    # finally, we use the indices and map the rankings with the questions themselves and \n",
    "    # store them in ques_ranking\n",
    "    ques_ranking = {}\n",
    "    for i in range(len(y_pred)):\n",
    "        ques_ranking[i] = dfn.iloc[ranking[i]]['Question']\n",
    "    for key in ques_ranking:\n",
    "        print(str(key)+\": \"+str(ques_ranking[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3afbd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the ANN built on the set of features extracted using Universal Sentence Encoder\n",
    "# A similar procedure as above is followed for this function\n",
    "def test_model_auto(fname, X):\n",
    "    dfn = pd.read_csv(fname)\n",
    "    y_pred = ann2.predict(X)\n",
    "    y_bi = y_pred.copy()\n",
    "    y_bi = (y_bi>0.5)\n",
    "    y_res = np.array(y_pred)\n",
    "    ranking = {}\n",
    "    for j in range(len(y_res)):\n",
    "        maxi = 0\n",
    "        for i in range(len(y_res)):\n",
    "            if y_res[i]>y_res[maxi]:\n",
    "                maxi=i\n",
    "        y_res[maxi] = 0       \n",
    "        ranking[j] = maxi\n",
    "    ques_ranking = {}\n",
    "    for i in range(len(y_pred)):\n",
    "        ques_ranking[i] = dfn.iloc[ranking[i]]['Question']\n",
    "    for key in ques_ranking:\n",
    "        print(str(key)+\": \"+str(ques_ranking[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd32dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from the questions, and remove redundant and irrelevant features\n",
    "def train_manual(fname, index):\n",
    "    df= pd.read_csv(fname)\n",
    "    \n",
    "    # Feature 1: Number of tokens in the question\n",
    "    token = []\n",
    "    for question in df['Question']:\n",
    "        fdist = FreqDist(question)\n",
    "        no_of_tokens = fdist.N()\n",
    "        token.append(no_of_tokens)\n",
    "    df['No_of_ques_tokens']=token\n",
    "    \n",
    "    # Feature 2: Number of tokens in answer to the question\n",
    "    token = []\n",
    "    for answer in df['Answer']:\n",
    "        fdist = FreqDist(answer)\n",
    "        no_of_tokens = fdist.N()\n",
    "        token.append(no_of_tokens)\n",
    "    df['No_of_ans_tokens']=token\n",
    "    \n",
    "    # Feature 3: Binary feature to indicate the presence of 'What' in the question\n",
    "    wh = []\n",
    "    sub_str = 'What'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['What'] = wh\n",
    "    \n",
    "    # Feature 4: Binary feature to indicate the presence of 'When' in the question\n",
    "    wh = []\n",
    "    sub_str = 'When'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['When'] = wh\n",
    "    \n",
    "    # Feature 5: Binary feature to indicate the presence of 'Why' in the question\n",
    "    wh = []\n",
    "    sub_str = 'Why'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['Why'] = wh\n",
    "    \n",
    "    # Feature 6: Binary feature to indicate the presence of 'Which' in the question\n",
    "    wh = []\n",
    "    sub_str = 'Which'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['Which'] = wh\n",
    "    \n",
    "    # Feature 7: Binary feature to indicate the presence of 'Whom' in the question\n",
    "    wh = []\n",
    "    sub_str = 'Whom'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['Whom'] = wh\n",
    "    \n",
    "    # Feature 8: Binary feature to indicate the presence of 'Where' in the question\n",
    "    wh = []\n",
    "    sub_str = 'Where'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['Where'] = wh\n",
    "    \n",
    "    # Feature 9: Binary feature to indicate the presence of 'Whose' in the question\n",
    "    wh = []\n",
    "    sub_str = 'Whose'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['Whose'] = wh\n",
    "    \n",
    "    # Feature 10: Binary feature to indicate the presence of 'Who' in the question\n",
    "    wh = []\n",
    "    sub_str = 'Who'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['Who'] = wh\n",
    "    \n",
    "    # Feature 11: Binary feature to indicate the presence of 'How' in the question\n",
    "    wh = []\n",
    "    sub_str = 'How'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str) == -1):\n",
    "            wh.append(0)\n",
    "        else:\n",
    "            wh.append(1)\n",
    "    df['How'] = wh\n",
    "    \n",
    "    # Feature 12: Binary feature to indicate the presence of negation in the question\n",
    "    neg = []\n",
    "    sub_str_1 = 'not'\n",
    "    sub_str_2 = 'never'\n",
    "    sub_str_3 = 'no'\n",
    "    for question in df['Question']:\n",
    "        if (question.find(sub_str_1) == -1 or question.find(sub_str_2)==-1 or question.find(sub_str_3==-1)):\n",
    "            neg.append(0)\n",
    "        else:\n",
    "            neg.append(1)\n",
    "    df['Negation'] = neg\n",
    "    \n",
    "    # Features 13-22: Counting the number of nouns, adjectives, prepositions, etc. to understand the strcutre \n",
    "    # of the sentence using POS tagging\n",
    "    nouns = []\n",
    "    proper_nouns = []\n",
    "    pronouns = []\n",
    "    conjunctions = []\n",
    "    adverbs = []\n",
    "    pasts = []\n",
    "    presents = []\n",
    "    prepositions = []\n",
    "    adjectives = []\n",
    "    numbers = []\n",
    "    for question in df['Question']:\n",
    "        lower_case = question.lower()\n",
    "        tokens = nltk.word_tokenize(lower_case)    \n",
    "        tags = pos_tag(tokens)\n",
    "        count = Counter( tag for word,  tag in tags)\n",
    "        proper_noun = count['NNP']+count['NNPS']\n",
    "        noun = count['NN']+count['NNS']\n",
    "        adjective = count['JJ']+count['JJR']+count['JJS']\n",
    "        pronoun = count['PRP'] +count['PRP$']\n",
    "        adverb = count['RB']+count['RBR']+count['RBS']\n",
    "        conjunction = count['CC']\n",
    "        number = count['CD']\n",
    "        preposition = count['IN']\n",
    "        past_tense = count['VBD']+count['VBN']\n",
    "        present_tense = count['VBP']+count['VBZ']\n",
    "        if past_tense>0:\n",
    "            past = 1\n",
    "        else:\n",
    "            past = 0\n",
    "        if present_tense>0:\n",
    "            present = 1\n",
    "        else:\n",
    "            present = 0\n",
    "        nouns.append(noun)\n",
    "        proper_nouns.append(proper_noun)\n",
    "        pronouns.append(pronoun)\n",
    "        conjunctions.append(conjunction)\n",
    "        adverbs.append(adverb)\n",
    "        pasts.append(past)\n",
    "        presents.append(present)\n",
    "        prepositions.append(preposition)\n",
    "        adjectives.append(adjective)\n",
    "        numbers.append(number)\n",
    "    df['noun'] = nouns\n",
    "    df['adjective'] = adjectives\n",
    "    df['proper_noun'] = proper_nouns\n",
    "    df['pronoun'] = pronouns\n",
    "    df['adverb'] = adverbs\n",
    "    df['conjuction'] = conjunctions\n",
    "    df['number'] = numbers\n",
    "    df['prepostion'] = prepositions\n",
    "    df['past_tense'] =pasts\n",
    "    df['present_tense']=presents\n",
    "    \n",
    "    # Feature 23: Flesch score to evaluate the reading difficulty\n",
    "    flesch = []\n",
    "    for question in df['Question']:\n",
    "        score = textstat.flesch_reading_ease(question)\n",
    "        flesch.append(score)\n",
    "    df['Reading_ease'] = flesch\n",
    "    \n",
    "    #Feature 24: Number of grammatical mistakes\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    mistakes = []\n",
    "    for question in df['Question']:\n",
    "        matches = tool.check(question)    \n",
    "        mistakes.append(len(matches))\n",
    "    df['No_of_grammar_errors'] = mistakes\n",
    "    \n",
    "    # index used to indicate if data that is being processed is training(index == 0), or test(index == 1)\n",
    "    if index !=1:\n",
    "        X = df.iloc[:, 3:]\n",
    "        X['target'] = df['Quality']\n",
    "        x = X.values #returns a numpy array\n",
    "        # Normalizing the dataset\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        normalized_df= pd.DataFrame(x_scaled)\n",
    "        normalized_df.to_csv('test0_done.csv')\n",
    "    \n",
    "        filename = 'test0_done.csv'\n",
    "        data = pd.read_csv(filename, header=None)\n",
    "        # retrieve numpy array\n",
    "        dataset = data.values\n",
    "        X = dataset[1:, 1:-1]\n",
    "        y = dataset[1:,-1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "        \n",
    "        #selecting best features and finding importance of each feature\n",
    "        X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "        # plot the scores for each feature using bar plot\n",
    "        pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "        pyplot.show()\n",
    "        df3 = pd.DataFrame(X)\n",
    "        cols = []\n",
    "        for i in range(df3.shape[1]):\n",
    "            cols.append(i)\n",
    "        df3.columns = cols\n",
    "        df3['target']=y\n",
    "        fs_scores = np.nan_to_num(fs.scores_)\n",
    "        # Setting the significance threshold as 0.05, and if score is below that, null hypothesis is\n",
    "        # accepted(which states that the feature has no significant impact on the performance), else\n",
    "        # the alternate hypothesis is accepted(which states that the feature does have a significant \n",
    "        # impact on the performance)\n",
    "        for i in range(len(fs_scores)):\n",
    "            if fs_scores[i]<0.05:\n",
    "                df3.drop(i, axis=1,inplace=True)\n",
    "            else:\n",
    "                sel_feat_man.append(i)\n",
    "        df3.to_csv('sel_feat_test0_done.csv')\n",
    "        df4 = pd.read_csv('sel_feat_test0_done.csv')\n",
    "        X = df4.iloc[1:, 1:-1].values\n",
    "        y = df4.iloc[1:,-1].values\n",
    "        # after feature selection, data is sent to train the ANN model\n",
    "        train_model_man(X, y)\n",
    "        \n",
    "    else:\n",
    "        # similar process as above is followed, except the features to be selected are already \n",
    "        # pre-decided, and stored in sel_feat_man\n",
    "        X = df.iloc[:, 2:]\n",
    "        x = X.values #returns a numpy array\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        df6= pd.DataFrame(x_scaled)\n",
    "        cols = []\n",
    "        for i in range(df6.shape[1]):\n",
    "            cols.append(i)\n",
    "        df6.columns = cols\n",
    "        for i in range(df6.shape[1]):\n",
    "            if i not in sel_feat_man:\n",
    "                df6.drop(i, axis=1,inplace=True)\n",
    "        df6.to_csv('test_feat.csv')\n",
    "        df4 = pd.read_csv('test_feat.csv')\n",
    "        X = df4.iloc[1:, 1:].values\n",
    "        test_model_man(fname, X)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6e576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auto(fname, index):\n",
    "    \n",
    "    df= pd.read_csv(fname)\n",
    "    # Extracting features from questions only, using Universal Sentence Encoder\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    embeddings = embed(df['Question'])\n",
    "    embeddings.shape[1]\n",
    "    \n",
    "    cols = []\n",
    "    for i in range(embeddings.shape[1]):\n",
    "        cols.append(i)\n",
    "    df2 = pd.DataFrame(embeddings, columns = cols)\n",
    "    # converting tensors to float values\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        for j in range(embeddings.shape[1]):\n",
    "            df2.iloc[i][j]=float(df2.iloc[i][j])\n",
    "            \n",
    "    # similar procedure as for manual features is followed here for sentence embedding, and feature selection\n",
    "    X = df2\n",
    "    if index != 1:\n",
    "        df2['target'] = df['Quality']\n",
    "        df2.to_csv('test0_done1.csv')\n",
    "        filename = 'test0_done1.csv'\n",
    "        data = pd.read_csv(filename, header=None)\n",
    "        # retrieve numpy array\n",
    "        dataset = data.values\n",
    "        X = dataset[1:, 1:-1]\n",
    "        y = dataset[1:,-1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "        X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "        # plot the scores\n",
    "        pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "        pyplot.show()\n",
    "        df3 = pd.DataFrame(X)\n",
    "        cols = []\n",
    "        for i in range(df3.shape[1]):\n",
    "            cols.append(i)\n",
    "        df3.columns = cols\n",
    "        df3['target']=y\n",
    "        import numpy as np\n",
    "        fs_scores = np.nan_to_num(fs.scores_)\n",
    "        for i in range(len(fs_scores)):\n",
    "            if fs_scores[i]<0.05:\n",
    "                df3.drop(i, axis=1,inplace=True)\n",
    "            else:\n",
    "                sel_feat_auto.append(i)\n",
    "        df3.to_csv('sel_feat_test.csv')\n",
    "        df4 = pd.read_csv('sel_feat_test.csv')\n",
    "        X = df4.iloc[1:, 1:-1].values\n",
    "        y = df4.iloc[1:,-1].values\n",
    "        # processed data sent to train ANN models\n",
    "        train_model_auto(X,y)\n",
    "    else:\n",
    "        x = X.values #returns a numpy array\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        normalized_df= pd.DataFrame(x_scaled)\n",
    "        for i in range(normalized_df.shape[1]):\n",
    "            if i not in sel_feat_auto:\n",
    "                normalized_df.drop(i, axis=1,inplace=True)\n",
    "        normalized_df.to_csv('test_feat1.csv')\n",
    "        df4 = pd.read_csv('test_feat1.csv')\n",
    "        X = df4.iloc[1:, 1:].values\n",
    "        test_model_auto(fname, X)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b5a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_manual(fname):\n",
    "    train_manual(fname, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "048aad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_auto(fname):\n",
    "    train_auto(fname, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "583b4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname1 is training dataset containing questions, answers, and the labels\n",
    "# fname is the test dataset containing only the questions, and answers\n",
    "fname1 = 'Quest_Training.csv'\n",
    "fname = 'Quest_Test.csv'\n",
    "sel_feat_man = []\n",
    "sel_feat_auto = []\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c13ed975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanid/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 4  6  8 11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/sanid/miniforge3/envs/tensorflow/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAALtElEQVR4nO3dbYhlBR3H8d+vdaVSo4e9SfjQVMRSBK0yWLEhqRWrRg9QoJBYFNMLDYUgtt5ULwLfVPYihElNITV6siR7kkpKKOuubvmwSiVbrtrulQitIFF/vbh3dmfHu3vP1D13/jPn+4Fh7sPx8j/c2S/Hc88510kEAKjreWs9AADg6Ag1ABRHqAGgOEINAMURagAo7pg2XnTLli2Zm5tr46UBYEPatWvX40l6455rJdRzc3Pq9/ttvDQAbEi2/3Kk59j1AQDFEWoAKG5iqG1vtb172c8Tti+fwWwAADXYR53kQUnbJMn2JkmPSLq53bEAAEtWu+vjHEl/TnLEnd4AgOlabagvkHTTuCdsL9ju2+4PBoP/fzIAgKRVhNr2sZLeLelb455PsphkPsl8rzf2UEAAwP9gNVvU50q6K8n+toYBADzXakJ9oY6w2wMA0J5GZybafqGkd0j6WLvjAN02t/PWRsvtveL8lidBJY1CneTfkl7W8iwAgDE4MxEAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiGl3rY5a4KA0AHI4tagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiuUahtv9j2t20/YHuP7be0PRgAYKjpKeRflvTjJO+3faykF7Y4EwBgmYmhtv0iSWdK+pAkJXlK0lPtjgUAWNJk18erJQ0kfc323bavtn3cyoVsL9ju2+4PBoOpDwoAXdUk1MdIOl3SVUlOk/QvSTtXLpRkMcl8kvlerzflMQGgu5qEep+kfUnuHN3/tobhBgDMwMRQJ/mbpIdtbx09dI6k+1udCgBwUNOjPj4u6YbRER8PSfpweyMBAJZrFOokuyXNtzsKAGAczkwEgOIINQAUV+7LbQFsDHxR9fSwRQ0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAortFXcdneK+lJSc9IejoJ30gOADOymu9MPCvJ461NAgAYi10fAFBc01BH0k9t77K9MG4B2wu2+7b7g8FgehMCQMc1DfX2JKdLOlfSJbbPXLlAksUk80nme73eVIcEgC5rFOokj45+H5B0s6Qz2hwKAHDIxFDbPs72CUu3Jb1T0r1tDwYAGGpy1MeJkm62vbT8jUl+3OpUAICDJoY6yUOS3jiDWQAAY3B4HgAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiiPUAFDcai5z2mlzO29ttNzeK85veRIAXcMWNQAUR6gBoDhCDQDFEWoAKI5QA0BxhBoAiuPwPHQOh1pivWGLGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxTUOte1Ntu+2/YM2BwIAHG41W9SXSdrT1iAAgPEahdr2yZLOl3R1u+MAAFZqukV9paRPSnq2vVEAAONMDLXtd0k6kGTXhOUWbPdt9weDwdQGBICua7JFvV3Su23vlfQNSWfb/vrKhZIsJplPMt/r9aY8JgB018RQJ/lUkpOTzEm6QNLPk3yw9ckAAJI4jhoAylvVZU6T3C7p9lYmmaGml7mUuNQlgLXHFjUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOJWdcIL0LamJyNxIhK6hC1qACiOUANAcYQaAIoj1ABQHKEGgOIINQAUx+F5ADDBWh82yhY1ABTHFjWATlnrreP/BVvUAFAcoQaA4gg1ABQ3MdS2n2/7t7Z/b/s+25+bxWAAgKEmHyb+R9LZSf5pe7OkO2z/KMlvWp4NAKAGoU4SSf8c3d08+kmbQwEADmm0j9r2Jtu7JR2QdFuSO1udCgBwUKNQJ3kmyTZJJ0s6w/YbVi5je8F233Z/MBhMeUwA6K5VHfWR5B+Sbpe0Y8xzi0nmk8z3er3pTAcAaHTUR8/2i0e3XyDp7ZIeaHkuAMBIk6M+XiHpetubNAz7N5P8oN2xAABLmhz18QdJp81gFgDAGJyZCADFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4gg1ABRHqAGgOEINAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaC4Jt/wgg1mbuetjZfde8X5LU4CoAm2qAGgOEINAMURagAojlADQHGEGgCKmxhq26fY/oXtPbbvs33ZLAYDAAw1OTzvaUmfSHKX7RMk7bJ9W5L7W54NAKAGW9RJHkty1+j2k5L2SDqp7cEAAEOr2kdte07SaZLuHPPcgu2+7f5gMJjSeACAxqG2fbyk70i6PMkTK59PsphkPsl8r9eb5owA0GmNQm17s4aRviHJd9sdCQCw3MQPE21b0jWS9iT5YvsjrV7Ta1dw3QoA61GTLertki6SdLbt3aOf81qeCwAwMnGLOskdkjyDWQAAY3BmIgAUR6gBoDhCDQDFEWoAKI5QA0BxfGciWsPx7cB0sEUNAMURagAojlADQHGEGgCKI9QAUByhBoDiCDUAFEeoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOK4zCmAdavppXSl9X053Ylb1LavtX3A9r2zGAgAcLgmuz6uk7Sj5TkAAEcwMdRJfinp7zOYBQAwxtT2UdtekLQgSaeeeuq0XhZAh/D1beNN7aiPJItJ5pPM93q9ab0sAHQeR30A61hXjnroOo6jBoDimhyed5OkX0vaanuf7Y+0PxYAYMnEXR9JLpzFIACA8dj1AQDFEWoAKI5QA0BxhBoAiiPUAFAcoQaA4jgzsRiudQBgJbaoAaA4Qg0AxRFqACiOUANAcYQaAIoj1ABQHKEGgOIINQAUR6gBoDjOTAQ6hrNf1x+2qAGgOEINAMURagAojlADQHGNQm17h+0Hbf/J9s62hwIAHDIx1LY3SfqKpHMlvV7ShbZf3/ZgAIChJofnnSHpT0kekiTb35D0Hkn3tzkYsN5tpMPgNtK6rEdOcvQF7PdL2pHko6P7F0l6U5JLVyy3IGlhdHerpAenOOcWSY9P8fXWG9af9Wf9N75XJumNe6LJFrXHPPacuidZlLS4ysEasd1PMt/Ga68HrD/rz/p3d/2lZh8m7pN0yrL7J0t6tJ1xAAArNQn17yS91varbB8r6QJJt7Q7FgBgycRdH0metn2ppJ9I2iTp2iT3tT7Z4VrZpbKOsP7dxvp33MQPEwEAa4szEwGgOEINAMWVDnXXT123vdf2PbZ32+6v9TyzYPta2wds37vssZfavs32H0e/X7KWM7blCOv+WduPjP4Gdts+by1nbJPtU2z/wvYe2/fZvmz0eCfe/6MpG2pOXT/orCTbOnQc6XWSdqx4bKeknyV5raSfje5vRNfpuesuSV8a/Q1sS/LDGc80S09L+kSS10l6s6RLRv/mu/L+H1HZUGvZqetJnpK0dOo6NrAkv5T09xUPv0fS9aPb10t67yxnmpUjrHtnJHksyV2j209K2iPpJHXk/T+ayqE+SdLDy+7vGz3WJZH0U9u7Rqfod9WJSR6Thv+YJb18jeeZtUtt/2G0a6QT/9tve07SaZLuFO9/6VA3OnV9g9ue5HQNd/9cYvvMtR4IM3eVpNdI2ibpMUlfWNNpZsD28ZK+I+nyJE+s9TwVVA51509dT/Lo6PcBSTdruDuoi/bbfoUkjX4fWON5ZibJ/iTPJHlW0le1wf8GbG/WMNI3JPnu6OHOvv9LKoe606eu2z7O9glLtyW9U9K9R/+vNqxbJF08un2xpO+v4SwztRSokfdpA/8N2LakayTtSfLFZU919v1fUvrMxNGhSFfq0Knrn1/biWbH9qs13IqWhqf639iF9bd9k6S3aXhpy/2SPiPpe5K+KelUSX+V9IEkG+5DtyOs+9s03O0RSXslfWxpf+1GY/utkn4l6R5Jz44e/rSG+6k3/Pt/NKVDDQCovesDACBCDQDlEWoAKI5QA0BxhBoAiiPUAFAcoQaA4v4LN27T6eNphWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.6899 - accuracy: 0.5365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 06:54:15.435025: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6892 - accuracy: 0.5404\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6750 - accuracy: 0.5808\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6670 - accuracy: 0.5960\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6597 - accuracy: 0.6111\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6526 - accuracy: 0.6111\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6454 - accuracy: 0.6616\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6407 - accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6327 - accuracy: 0.6616\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6259 - accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.6869\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6103 - accuracy: 0.7071\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5998 - accuracy: 0.6919\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.6919\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5864 - accuracy: 0.6919\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5810 - accuracy: 0.6970\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5693 - accuracy: 0.7222\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5603 - accuracy: 0.6970\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5578 - accuracy: 0.7071\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5532 - accuracy: 0.7121\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5430 - accuracy: 0.7475\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7323\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7323\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7222\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7323\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7576\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7475\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7525\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.7576\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7525\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7828\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7828\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7828\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7778\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7727\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7778\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7828\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7828\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7778\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.8030\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8030\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.7980\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.7929\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8081\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8081\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8131\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.8081\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.7980\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8283\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8283\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8232\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8232\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8232\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8384\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8232\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8485\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8384\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8434\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8434\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3484 - accuracy: 0.8434\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8434\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3196 - accuracy: 0.8687\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8636\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3396 - accuracy: 0.8283\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8131\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3037 - accuracy: 0.8687\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8535\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8586\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2847 - accuracy: 0.8788\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2872 - accuracy: 0.8838\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3085 - accuracy: 0.8535\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8434\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8283\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3317 - accuracy: 0.8586\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.8636\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.8939\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2741 - accuracy: 0.8838\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2548 - accuracy: 0.8788\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2460 - accuracy: 0.8838\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2445 - accuracy: 0.8838\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2327 - accuracy: 0.8990\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2393 - accuracy: 0.8889\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.8990\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9141\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2169 - accuracy: 0.9293\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9141\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2130 - accuracy: 0.9040\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2220 - accuracy: 0.8838\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2147 - accuracy: 0.9091\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.8737\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2303 - accuracy: 0.8838\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2492 - accuracy: 0.8889\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2376 - accuracy: 0.8990\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2106 - accuracy: 0.9141\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2292 - accuracy: 0.9040\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2006 - accuracy: 0.9141\n"
     ]
    }
   ],
   "source": [
    "train_manual(fname1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4a68aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 06:54:39.364686: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2d4239040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: What was the name of the short code that Odeo initially considered as a short code?\n",
      "1: Who developed the first Twitter prototype?\n",
      "2: How many conferencegoers kept tabs on each other via constant twitters?\n",
      "3: What was the definition of the word twitter?\n",
      "4: Who said that Twitter was absolutely ruling SXSWi?\n",
      "5: How many tweets were posted per quarter in 2008?\n",
      "6: What did Twitter describe as in the beginning?\n",
      "7: What did Williams call Twitter a social network?\n",
      "8: How did Twitter change from what we thought it was a social network?\n",
      "9: Who remarked on Newsweek?\n",
      "10: What was Twitter more than a social network?\n",
      "11: How many Williams fired Glass?\n",
      "12: How many tweets did Twitter use per day during the 2007 South by Southwest Interactive SXSWi conference?\n",
      "13: How many people responded to the SXSWi conference?\n",
      "14: What was the name of the company that created the first Twitter prototype?\n",
      "15: How many Twitter staff received the Web Award?\n",
      "16: What company did Biz Stone, Evan Williams, and Dorsey form in 2006?\n",
      "17: How many Twitter staff received the festival s Web Award?\n",
      "18: How many words did Dorsey explain the origin of the Twitter title?\n",
      "19: Who mentioned the service?\n",
      "20: How many tweets did Twitter have per quarter in 2007?\n",
      "21: In what year was the South by Southwest Interactive SXSWi conference?\n",
      "22: Who said Twitter was owning the SXSWi conference?\n",
      "23: When did the project begin?\n",
      "24: How many interviews did Williams provide insight into the ambiguity that defined this early period in 2013?\n",
      "25: What was the definition of twitter?\n",
      "26: Who introduced the idea of an individual using an SMS service to communicate with a small group?\n",
      "27: When was the full version of Twitter released?\n",
      "28: What was the name of the disemvowelled version of the word twitter?\n",
      "29: When did 31 Twitter spin off into its own company?\n",
      "30: What was Odeo's name changed to?\n"
     ]
    }
   ],
   "source": [
    "test_manual(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5edb5ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 07:00:38.540445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-11 07:00:40.143635: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/7 [===>..........................] - ETA: 1s - loss: 0.6881 - accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 07:01:23.482023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6919 - accuracy: 0.5808\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6862 - accuracy: 0.5859\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.5859\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6778 - accuracy: 0.5859\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6735 - accuracy: 0.5859\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6680 - accuracy: 0.5859\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6615 - accuracy: 0.5859\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6557 - accuracy: 0.5859\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6489 - accuracy: 0.5859\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6426 - accuracy: 0.5859\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6362 - accuracy: 0.5859\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6294 - accuracy: 0.5859\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.5859\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.5859\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6117 - accuracy: 0.5859\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6062 - accuracy: 0.5859\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6006 - accuracy: 0.5859\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5948 - accuracy: 0.5859\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5895 - accuracy: 0.5859\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5837 - accuracy: 0.5859\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.5859\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.5859\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5680 - accuracy: 0.5859\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5624 - accuracy: 0.5859\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.5859\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.5859\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5465 - accuracy: 0.5859\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5408 - accuracy: 0.7222\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7424\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7828\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7677\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7778\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7778\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7879\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.8030\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.8081\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.8131\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.8131\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.8232\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.8232\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.8384\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8434\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.8485\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.8535\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8535\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.8636\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.8687\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8737\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8737\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8788\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8788\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8889\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8889\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.9040\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8939\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.9040\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.9192\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.9141\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.9192\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.9192\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3601 - accuracy: 0.9192\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.9242\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.9242\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.9242\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3443 - accuracy: 0.9242\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3401 - accuracy: 0.9242\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3362 - accuracy: 0.9242\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.9242\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.9293\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3256 - accuracy: 0.9343\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3219 - accuracy: 0.9394\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3187 - accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3151 - accuracy: 0.9495\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3113 - accuracy: 0.9495\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.9495\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3045 - accuracy: 0.9545\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3011 - accuracy: 0.9545\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2980 - accuracy: 0.9646\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2954 - accuracy: 0.9646\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2929 - accuracy: 0.9596\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.9646\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2868 - accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2834 - accuracy: 0.9646\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2805 - accuracy: 0.9646\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2767 - accuracy: 0.9747\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.9747\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2716 - accuracy: 0.9747\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2683 - accuracy: 0.9747\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2656 - accuracy: 0.9747\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.9798\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2599 - accuracy: 0.9899\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2578 - accuracy: 0.9899\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2549 - accuracy: 0.9899\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2523 - accuracy: 0.9899\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.9899\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2489 - accuracy: 0.9899\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2457 - accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 07:01:27.585446: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "ann2 = tf.keras.models.Sequential()\n",
    "train_auto(fname1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b34477dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 07:02:20.310247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-11 07:02:21.970608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-11 07:02:29.449627: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x33a02fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2022-05-11 07:02:29.486648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: What was the name of the company that created the first Twitter prototype?\n",
      "1: Who introduced the idea of an individual using an SMS service to communicate with a small group?\n",
      "2: What was the name of the disemvowelled version of the word twitter?\n",
      "3: What was Odeo's name changed to?\n",
      "4: What was the name of the short code that Odeo initially considered as a short code?\n",
      "5: When did the project begin?\n",
      "6: How many words did Dorsey explain the origin of the Twitter title?\n",
      "7: What was the definition of the word twitter?\n",
      "8: Who developed the first Twitter prototype?\n",
      "9: When did 31 Twitter spin off into its own company?\n",
      "10: How many interviews did Williams provide insight into the ambiguity that defined this early period in 2013?\n",
      "11: What did Williams call Twitter a social network?\n",
      "12: How did Twitter change from what we thought it was a social network?\n",
      "13: What did Twitter describe as in the beginning?\n",
      "14: How many tweets did Twitter use per day during the 2007 South by Southwest Interactive SXSWi conference?\n",
      "15: How many people responded to the SXSWi conference?\n",
      "16: How many Twitter staff received the Web Award?\n",
      "17: How many tweets did Twitter have per quarter in 2007?\n",
      "18: How many tweets were posted per quarter in 2008?\n",
      "19: What was the definition of twitter?\n",
      "20: What company did Biz Stone, Evan Williams, and Dorsey form in 2006?\n",
      "21: How many Williams fired Glass?\n",
      "22: Who mentioned the service?\n",
      "23: What was Twitter more than a social network?\n",
      "24: When was the full version of Twitter released?\n",
      "25: Who said that Twitter was absolutely ruling SXSWi?\n",
      "26: Who remarked on Newsweek?\n",
      "27: How many conferencegoers kept tabs on each other via constant twitters?\n",
      "28: How many Twitter staff received the festival s Web Award?\n",
      "29: Who said Twitter was owning the SXSWi conference?\n",
      "30: In what year was the South by Southwest Interactive SXSWi conference?\n"
     ]
    }
   ],
   "source": [
    "test_auto(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a55ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniforge3-tensorflow] *",
   "language": "python",
   "name": "conda-env-miniforge3-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
